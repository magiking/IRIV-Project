{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains the python code that we used to create a linear SVM using `sklearn`.\n",
    "For this to run correctly, make sure that you have the 'cat/' folder with the corpus of training documents, and the 'tweets/' folder, with the tweets from the different cities in the same directory as this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import re  \n",
    "import nltk  \n",
    "from sklearn.datasets import load_files  \n",
    "nltk.download('stopwords')  \n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the category folder\n",
    "film_data = load_files('./cat')\n",
    "X, y = film_data.data, film_data.target  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music\n",
      "music\n",
      "sports\n",
      "music\n",
      "film\n",
      "film\n",
      "music\n",
      "sports\n",
      "sports\n",
      "music\n"
     ]
    }
   ],
   "source": [
    "# See the categories of some of the documents in the target set\n",
    "for t in film_data.target[:10]:\n",
    "    print(film_data.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process text\n",
    "stemmer = PorterStemmer()\n",
    "documents = []\n",
    "\n",
    "for sen in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    # document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = [stemmer.stem(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectorizer to make feature vectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "tfidfconverter = TfidfTransformer()  \n",
    "X = tfidfconverter.fit_transform(X).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into testing and training sets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one of the two cells below to make a different classifier. and see the difference in accuracy between the naieve bayes model and the linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a classifier with Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier with linear SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have made a classifier, test its accuracy on with the cell below. Try both naieve bayes and linear SVM and see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 1 0]\n",
      " [0 2 0]\n",
      " [0 0 2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.93         8\n",
      "          1       0.67      1.00      0.80         2\n",
      "          2       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       0.94      0.92      0.92        12\n",
      "\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# test predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to run predictions on our tweets.\n",
    "Change the value of `city` in the cells below to either 'SanDiego', 'NewYork', or 'Denver' to run the classifier on a different city, or to see the results from a different city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets/NewYork/21990748/tweets.json\n",
      "tweets/NewYork/21734241/tweets.json\n",
      "tweets/NewYork/218617107/tweets.json\n",
      "tweets/NewYork/156720500/tweets.json\n",
      "tweets/NewYork/64467795/tweets.json\n",
      "tweets/NewYork/245272915/tweets.json\n",
      "tweets/NewYork/556256860/tweets.json\n",
      "tweets/NewYork/255812611/tweets.json\n",
      "tweets/NewYork/43040265/tweets.json\n",
      "tweets/NewYork/304627263/tweets.json\n",
      "tweets/NewYork/20551303/tweets.json\n",
      "tweets/NewYork/30155972/tweets.json\n",
      "tweets/NewYork/284274787/tweets.json\n",
      "tweets/NewYork/3014741/tweets.json\n",
      "tweets/NewYork/21030857/tweets.json\n",
      "tweets/NewYork/466744226/tweets.json\n",
      "tweets/NewYork/315142011/tweets.json\n",
      "tweets/NewYork/90926420/tweets.json\n",
      "tweets/NewYork/426962930/tweets.json\n",
      "tweets/NewYork/1977157224/tweets.json\n",
      "tweets/NewYork/159762740/tweets.json\n",
      "tweets/NewYork/335946517/tweets.json\n",
      "tweets/NewYork/254108775/tweets.json\n",
      "tweets/NewYork/65431946/tweets.json\n",
      "tweets/NewYork/48849410/tweets.json\n",
      "tweets/NewYork/22320759/tweets.json\n",
      "tweets/NewYork/874650841/tweets.json\n",
      "tweets/NewYork/120269494/tweets.json\n",
      "tweets/NewYork/536382902/tweets.json\n",
      "tweets/NewYork/2902954425/tweets.json\n",
      "tweets/NewYork/119867108/tweets.json\n",
      "tweets/NewYork/482357199/tweets.json\n",
      "tweets/NewYork/471628288/tweets.json\n",
      "tweets/NewYork/90573676/tweets.json\n",
      "tweets/NewYork/12701412/tweets.json\n",
      "tweets/NewYork/1968846060/tweets.json\n",
      "tweets/NewYork/1320771006/tweets.json\n",
      "tweets/NewYork/15564022/tweets.json\n",
      "tweets/NewYork/27944885/tweets.json\n",
      "tweets/NewYork/20989174/tweets.json\n",
      "tweets/NewYork/446698606/tweets.json\n",
      "tweets/NewYork/255392715/tweets.json\n",
      "tweets/NewYork/948902065/tweets.json\n",
      "tweets/NewYork/72198806/tweets.json\n",
      "tweets/NewYork/1465548618/tweets.json\n",
      "tweets/NewYork/48061907/tweets.json\n",
      "tweets/NewYork/55842014/tweets.json\n",
      "tweets/NewYork/295855693/tweets.json\n",
      "tweets/NewYork/1426548096/tweets.json\n",
      "tweets/NewYork/52437361/tweets.json\n",
      "tweets/NewYork/1879921752/tweets.json\n",
      "tweets/NewYork/19049847/tweets.json\n",
      "tweets/NewYork/378018987/tweets.json\n",
      "tweets/NewYork/1251314690/tweets.json\n",
      "tweets/NewYork/774510134/tweets.json\n",
      "tweets/NewYork/164060400/tweets.json\n",
      "tweets/NewYork/310374952/tweets.json\n",
      "tweets/NewYork/173984997/tweets.json\n",
      "tweets/NewYork/625086194/tweets.json\n",
      "tweets/NewYork/4345931/tweets.json\n",
      "tweets/NewYork/36348724/tweets.json\n",
      "tweets/NewYork/754289204/tweets.json\n",
      "tweets/NewYork/48747397/tweets.json\n",
      "tweets/NewYork/110639889/tweets.json\n",
      "tweets/NewYork/37093408/tweets.json\n",
      "tweets/NewYork/38452560/tweets.json\n",
      "tweets/NewYork/22000141/tweets.json\n",
      "tweets/NewYork/2743183980/tweets.json\n",
      "tweets/NewYork/455024449/tweets.json\n",
      "tweets/NewYork/24134103/tweets.json\n",
      "tweets/NewYork/15029864/tweets.json\n",
      "tweets/NewYork/46150701/tweets.json\n",
      "tweets/NewYork/29280295/tweets.json\n",
      "tweets/NewYork/299970114/tweets.json\n",
      "tweets/NewYork/138804723/tweets.json\n",
      "tweets/NewYork/589309307/tweets.json\n",
      "tweets/NewYork/86383503/tweets.json\n",
      "tweets/NewYork/237548529/tweets.json\n",
      "tweets/NewYork/268476335/tweets.json\n",
      "tweets/NewYork/140580807/tweets.json\n",
      "tweets/NewYork/133929829/tweets.json\n",
      "tweets/NewYork/467009841/tweets.json\n",
      "tweets/NewYork/54953050/tweets.json\n",
      "tweets/NewYork/158494257/tweets.json\n",
      "tweets/NewYork/66368876/tweets.json\n",
      "tweets/NewYork/932785717/tweets.json\n",
      "tweets/NewYork/63190463/tweets.json\n",
      "tweets/NewYork/709045724/tweets.json\n",
      "tweets/NewYork/287453334/tweets.json\n",
      "tweets/NewYork/419784857/tweets.json\n",
      "tweets/NewYork/199826263/tweets.json\n",
      "tweets/NewYork/82391708/tweets.json\n",
      "tweets/NewYork/26642790/tweets.json\n",
      "tweets/NewYork/548027106/tweets.json\n",
      "tweets/NewYork/225516240/tweets.json\n",
      "tweets/NewYork/274656986/tweets.json\n",
      "tweets/NewYork/66721068/tweets.json\n",
      "tweets/NewYork/460750312/tweets.json\n",
      "tweets/NewYork/97682949/tweets.json\n",
      "tweets/NewYork/355285163/tweets.json\n",
      "tweets/NewYork/363250131/tweets.json\n",
      "tweets/NewYork/272112899/tweets.json\n",
      "tweets/NewYork/6573352/tweets.json\n",
      "tweets/NewYork/53189333/tweets.json\n",
      "tweets/NewYork/2497275697/tweets.json\n",
      "tweets/NewYork/460520481/tweets.json\n",
      "tweets/NewYork/239563902/tweets.json\n",
      "tweets/NewYork/488626886/tweets.json\n",
      "tweets/NewYork/90704522/tweets.json\n",
      "tweets/NewYork/148969919/tweets.json\n",
      "tweets/NewYork/142330163/tweets.json\n",
      "tweets/NewYork/994638114/tweets.json\n",
      "tweets/NewYork/2891956636/tweets.json\n",
      "tweets/NewYork/50382296/tweets.json\n",
      "tweets/NewYork/949899295/tweets.json\n",
      "tweets/NewYork/217304598/tweets.json\n",
      "tweets/NewYork/39496172/tweets.json\n",
      "tweets/NewYork/21312248/tweets.json\n",
      "tweets/NewYork/11744152/tweets.json\n",
      "tweets/NewYork/383997228/tweets.json\n",
      "tweets/NewYork/35825744/tweets.json\n",
      "tweets/NewYork/369123575/tweets.json\n",
      "tweets/NewYork/49700792/tweets.json\n",
      "tweets/NewYork/27468202/tweets.json\n",
      "tweets/NewYork/23912766/tweets.json\n",
      "tweets/NewYork/190318706/tweets.json\n",
      "tweets/NewYork/14212076/tweets.json\n",
      "tweets/NewYork/73279371/tweets.json\n",
      "tweets/NewYork/25203002/tweets.json\n",
      "tweets/NewYork/1259522424/tweets.json\n",
      "tweets/NewYork/2883463365/tweets.json\n",
      "tweets/NewYork/172893981/tweets.json\n",
      "tweets/NewYork/1022745307/tweets.json\n",
      "tweets/NewYork/14403440/tweets.json\n",
      "tweets/NewYork/546135718/tweets.json\n",
      "tweets/NewYork/2966995028/tweets.json\n",
      "tweets/NewYork/21115632/tweets.json\n",
      "tweets/NewYork/16661097/tweets.json\n",
      "tweets/NewYork/253969634/tweets.json\n",
      "tweets/NewYork/565919881/tweets.json\n",
      "tweets/NewYork/22029607/tweets.json\n",
      "tweets/NewYork/31187903/tweets.json\n",
      "tweets/NewYork/38428725/tweets.json\n",
      "tweets/NewYork/18266688/tweets.json\n",
      "tweets/NewYork/473311723/tweets.json\n",
      "tweets/NewYork/157684364/tweets.json\n",
      "tweets/NewYork/14270329/tweets.json\n",
      "tweets/NewYork/2573501755/tweets.json\n",
      "tweets/NewYork/64081240/tweets.json\n",
      "tweets/NewYork/14338406/tweets.json\n",
      "tweets/NewYork/18699572/tweets.json\n",
      "tweets/NewYork/1343229756/tweets.json\n",
      "tweets/NewYork/110775637/tweets.json\n",
      "tweets/NewYork/526787104/tweets.json\n",
      "tweets/NewYork/793961694/tweets.json\n",
      "tweets/NewYork/20742461/tweets.json\n",
      "tweets/NewYork/210238655/tweets.json\n",
      "tweets/NewYork/503616430/tweets.json\n",
      "tweets/NewYork/538191247/tweets.json\n",
      "tweets/NewYork/314797639/tweets.json\n",
      "tweets/NewYork/1944104976/tweets.json\n",
      "tweets/NewYork/72033671/tweets.json\n",
      "tweets/NewYork/292444688/tweets.json\n",
      "tweets/NewYork/82328859/tweets.json\n",
      "tweets/NewYork/17314478/tweets.json\n",
      "tweets/NewYork/2932866452/tweets.json\n",
      "tweets/NewYork/459551103/tweets.json\n"
     ]
    }
   ],
   "source": [
    "# predicting on tweets\n",
    "import json\n",
    "import os\n",
    "\n",
    "city = 'NewYork'\n",
    "\n",
    "\n",
    "for root, dirs, files, in os.walk('tweets/{}'.format(city)):\n",
    "    for dirname in dirs:\n",
    "        tweets = {}\n",
    "        docs_new = []\n",
    "\n",
    "        # classifying each tweet from user\n",
    "        tweets_fname = 'tweets/{}/{}/tweets.json'.format(city, dirname)\n",
    "        onedoc_fname = 'tweets/{}/{}/text.txt'.format(city, dirname)\n",
    "        t_results_fname = 'tweets/{}/{}/t_results.json'.format(city, dirname)\n",
    "        o_results_fname = 'tweets/{}/{}/o_results.json'.format(city, dirname)\n",
    "        print(tweets_fname)\n",
    "        with open(tweets_fname, 'r') as f:\n",
    "            tweets = json.loads(f.read())\n",
    "        for tweet in tweets:\n",
    "            docs_new.append(tweet['text'])\n",
    "\n",
    "        X_new_counts = vectorizer.transform(docs_new)\n",
    "        X_new_tfidf = tfidfconverter.transform(X_new_counts)\n",
    "\n",
    "        predicted = classifier.predict(X_new_tfidf)\n",
    "        \n",
    "\n",
    "        results = []\n",
    "        for i in range(0, len(tweets)):\n",
    "            results.append({'doc': tweets[i]['text'], 'id': tweets[i]['id'], \n",
    "                            'pred_num': int(predicted[i]), 'pred_cat': film_data.target_names[predicted[i]]})\n",
    "            \n",
    "        # Write results\n",
    "        with open(t_results_fname, 'w') as f:\n",
    "            f.write(json.dumps(results))\n",
    "\n",
    "        # Classifying aggregate of user's tweets\n",
    "        docs_new.clear()\n",
    "        with open(onedoc_fname, 'r') as f:\n",
    "            docs_new.append(f.read())\n",
    "\n",
    "        X_new_counts = vectorizer.transform(docs_new)\n",
    "        X_new_tfidf = tfidfconverter.transform(X_new_counts)\n",
    "\n",
    "        predicted = classifier.predict(X_new_tfidf)\n",
    "\n",
    "        # write results\n",
    "        with open(o_results_fname, 'w') as f:\n",
    "            result = {'pred_num': int(predicted[0]), 'pred_cat': film_data.target_names[predicted[0]]}\n",
    "            f.write(json.dumps(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports:123 0.7365269461077845\n",
      "film:44 0.2634730538922156\n"
     ]
    }
   ],
   "source": [
    "# looking at users results\n",
    "from collections import Counter\n",
    "\n",
    "cat_counts = Counter()\n",
    "city = 'NewYork'\n",
    "results = []\n",
    "total_users = 0\n",
    "for root, dirs, files, in os.walk('tweets/{}'.format(city)):\n",
    "    for dirname in dirs:\n",
    "        total_users += 1\n",
    "        o_results_fname = 'tweets/{}/{}/o_results.json'.format(city, dirname)\n",
    "        with open(o_results_fname, 'r') as f:\n",
    "            result = json.loads(f.read())\n",
    "            results.append(result['pred_cat'])\n",
    "            \n",
    "cat_counts = Counter(results)\n",
    "for k,val in cat_counts.items():\n",
    "    print('{}:{} {}'.format(k, val, val/total_users))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film:9128 0.2795626473921166\n",
      "music:4841 0.14826498422712933\n",
      "sports:18682 0.572172368380754\n"
     ]
    }
   ],
   "source": [
    "# looking at results of tweets\n",
    "city = 'NewYork'\n",
    "cat_counts = Counter()\n",
    "tweets = 0\n",
    "for root, dirs, files, in os.walk('tweets/{}'.format(city)):\n",
    "    for dirname in dirs:\n",
    "        results = {}\n",
    "        cats = []\n",
    "        t_results_fname = 'tweets/{}/{}/t_results.json'.format(city, dirname)\n",
    "        with open(t_results_fname, 'r') as f:\n",
    "            results = json.loads(f.read())\n",
    "        tweets += len(results)\n",
    "        for tweet in results:\n",
    "            cats.append(tweet['pred_cat'])\n",
    "        cat_counts.update(cats)\n",
    "        \n",
    "for k,val in cat_counts.items():\n",
    "    print('{}:{} {}'.format(k, val, val/tweets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some outpus from each cell with the different cities using the linear SVM\n",
    "# SanDiego \n",
    "\n",
    "## Users\n",
    "     count %\n",
    "film:43 0.172\n",
    "sports:206 0.824\n",
    "music:1 0.004\n",
    "\n",
    "## Tweets\n",
    "film:13123 0.26803513071895424\n",
    "sports:28805 0.5883374183006536\n",
    "music:7032 0.14362745098039215\n",
    "\n",
    "# NewYork\n",
    "\n",
    "## Users\n",
    "sports:123 0.7365269461077845\n",
    "film:44 0.2634730538922156\n",
    "\n",
    "## Tweets\n",
    "film:9128 0.2795626473921166\n",
    "music:4841 0.14826498422712933\n",
    "sports:18682 0.572172368380754\n",
    "\n",
    "# Denver\n",
    "\n",
    "## Users\n",
    "sports:168 0.9032258064516129\n",
    "film:18 0.0967741935483871\n",
    "\n",
    "## Tweets\n",
    "sports:22391 0.6072464947251376\n",
    "film:9513 0.25799365389309253\n",
    "music:4969 0.13475985138176985\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "import pickle\n",
    "with open('text_classifier', 'wb') as picklefile:  \n",
    "    pickle.dump(classifier,picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
